{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "gIfDvo9L0UH2"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -  Yes Bank Stock Closing Price Prediction\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Regression\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1 -**  Nayana salve\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes Bank is an wellknown bank in india which provides wide range of services and solutions right from bank accounts,deposits,cards,cash,management,privilege banking,trade finance. Non-Resident India(NRI)banking, Institutionl banking,merchant acquiring, digital banking and agricultural banking solutions. As the data is all about the stock price so. In this project i will be analyzing the patterns of the dataset by performing exploratory data analysis and try to build a model with the help of machine learning for predicting the closing stock price.                                                                    \n",
        "\n",
        "The tools for data analysis and model building used in this project are the packages from python library such as Numpy and pandas,Matplotlib,Seaborn,Linear Regression,lasso,Ridge,ElasticNet,Minmaxscaler etc.\n"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/nayanasalve/Final-ML-Project"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The given data set contains stock price information in the various columns by monthly data. There are 5 columns in the data set such are Date,open,high,low,closing price. Our target variable here is the closing price column which we will try to predict for future. So first we will perform some exploratory data analysis to the data try to find out some pattern as well as see the relation between the various column and the target variable column. Then we will be building a model through which we will be able to predict or provide a decent estimate of the closing price which is our target variable."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Define Your Business Objective?**"
      ],
      "metadata": {
        "id": "PH-0ReGfmX4f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "N/A"
      ],
      "metadata": {
        "id": "PhDvGCAqmjP1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 20 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import math\n",
        "from datetime import datetime\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import (Lasso,Ridge,ElasticNet)\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import (mean_squared_error,mean_absolute_percentage_error,mean_absolute_error)\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "from sklearn import metrics\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "f_5BEh4BYOT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "path=(\"/content/drive/MyDrive/Colab Notebooks/drive/data_YesBank_StockPrices.csv\")\n",
        "YB_df=pd.read_csv(path)"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "YB_df.sample(5)"
      ],
      "metadata": {
        "id": "0WZr-UuBdsGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "YB_df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "YB_df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "YB_df.duplicated().sum()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "YB_df.isnull().sum().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**There is no missing values in the data set**"
      ],
      "metadata": {
        "id": "hxBk5LrKfOAb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset contains 185 rows and 5 columns with different variable types. There are no missing values as well as duplicate values in the dataset. There are 2 type of information inside the columns as float and object. Basically the given dataset is providing us the overview of the stock price details information and by generating the insight from those we will try to see the relations between our target variable(closing price) and the independent variables that are the other 4 columns. Then we will try to predict or provide the estimates of the future closing price  by building machine learning algorithm models."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "YB_df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "YB_df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Variables Description**"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The name of the individual variables mentioned in the columns of the data set and the discriptions of them are listed below:\n",
        "* Date - Month and day information on which the information was recorded.(categorical)\n",
        "* Open - Opening stock price.(Numeric)\n",
        "* High - Highest Stock price.(Numeric)\n",
        "* Low - Lowest stock price.(Numeric)\n",
        "* Close - Closing stock price.(Numeric)\n"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Check Unique Values for each variable.**"
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for items in YB_df.columns.tolist():\n",
        "  print('The number of uniques values in columns',items,'is',YB_df[items].nunique())"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "YB_df['High'].unique()"
      ],
      "metadata": {
        "id": "uxZbOfC6pv2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "YB_df['Open'].unique()"
      ],
      "metadata": {
        "id": "E60b-4Nwp30o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "YBC_df=YB_df.copy()"
      ],
      "metadata": {
        "id": "kx1V6OaJqKnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "YBC_df.head()"
      ],
      "metadata": {
        "id": "jgv7Sb-6qKfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "YBC_df['Date']=pd.to_datetime(YBC_df['Date'].apply(lambda x:datetime.strptime(x, '%b-%y')))"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "YBC_df.head()"
      ],
      "metadata": {
        "id": "tw48YkPtroyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The given data set does not have any missing values and null values.Also there are no duplicate values in the data set as i have cheacked already. Since the 'Date' column was not arranged in proper format. I have change the 'Date' column into the format year-month-date that will be helpful to visualize the data."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Univariate Analysis\n"
      ],
      "metadata": {
        "id": "WeP7pJA-tfMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "# Dependent Variable 'price'\n",
        "plt.figure(figsize=(15,10))\n",
        "sns.distplot(YBC_df['Close'], color=\"g\")"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To see the distribution of closing price in the dataset i have used the dist plot as with the help of dist plot i will be able to check the skewness of the data and according to that data will be transformed to handle the skewness."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above chart shows that the 'Close' columnm data is possitively skewed. So I have to transform this column data to log scale data for handling the skewness.\n",
        "\n"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes the gain insight shows the possitive skewed distribution of the 'Close' column that will help me to understand and methods to be applied to tackle the skewness of the data."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_features = YBC_df.describe().columns"
      ],
      "metadata": {
        "id": "WfRBhfTuvPdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_features"
      ],
      "metadata": {
        "id": "6GLmkJrFvPVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "for col in numeric_features:\n",
        "  fig = plt.figure(figsize=(9,6))\n",
        "  ax = fig.gca()\n",
        "  features = YBC_df[col]\n",
        "  features.hist(bins=50, ax=ax)\n",
        "  ax.axvline(features.mean(), color='y', linestyle='dashed', linewidth=2)\n",
        "  ax.axvline(features.median(), color='m', linestyle='dashed', linewidth=2)\n",
        "  ax.set_title(col)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As histogram is a very popular tool so that chart will show the overview of each and every variable information and gives a clear idea about the data set. It also sumarizes the measured data."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above chart it can be clearly seen that all the numeric variables are possitively skewed. So i have to transform these column dates to log scale data to handling the skewness."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes the gain insight shows the possitive skewed distribution of all the numeric columns that will help me to understands and the methods to be applied to tackel the skewness of the data."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "fig = plt.figure(figsize=(10,6))\n",
        "ax = fig.gca()\n",
        "features = YBC_df['Date']\n",
        "features.hist(bins=50, ax=ax)\n",
        "ax.axvline(features.mean(), color='Red',  linestyle= 'dashed', linewidth=2)\n",
        "ax.axvline(features.median(), color= 'magenta', linestyle = 'dashed', linewidth= 2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To see the distribution of 'Date' coloumn which is a categorical in the dataset i have used the dist plot."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the date coloumn is categorical information and from the distrogram plot it is clear that the data coloumn is equaly distributed."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bivariate Analysis"
      ],
      "metadata": {
        "id": "18hzIIEO0ZMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "ax=px.line(YBC_df,YBC_df['Date'],YBC_df['Close'], title= 'Monthly Closing price')\n",
        "ax.update_layout(xaxis=dict(title='Year'), yaxis=dict(title='Closing price'))\n",
        "ax.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As i am doing the bivariate analysis. Therefore the above line plot shows the relationship between the 'Date' column and the closing price."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above chart it can be seen that consistan overall growth in in the stock price till 2014 afcource wih some downfalls. But after 2014 the stock price started raise high and from 2016 through 2018 the growth was very impressive some times the stock price raised to over 350. But in the year of 2020 there was heavy downfall in the stock price. The reason must be a fraud case for which one of the founder of the bank"
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes the gained insight is showing the overall trends of the stock price throughout the year. By just seeing the trend we can have an idea as when to invest for buying yes bank shares."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "fig = plt.figure(figsize=(9,6))\n",
        "ax = fig.gca()\n",
        "features = YBC_df['Open']\n",
        "label = YBC_df['Close']\n",
        "correlation = features.corr(label)\n",
        "plt.scatter(x=features, y=label)\n",
        "plt.xlabel('Open')\n",
        "plt.ylabel('Close')\n",
        "ax.set_title('Close VS' + 'Open' + '- correlation:' + str(correlation))\n",
        "z = np.polyfit(YBC_df['Open'], YBC_df['Close'], 1)\n",
        "y_hat = np.poly1d(z)(YBC_df['Open'])\n",
        "\n",
        "plt.plot(YBC_df['Open'], y_hat, \"r--\", lw=1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above scatter plot shows the relation between the open and close."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see that the Open and Close data are Highly correlated therefore we can say that the closing price is very much dependent upon the Opening price of the stock."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes. The high correlation between the open and price indicates that Opening price willalways play important role to have an idea abouti closing price."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "fig = plt.figure(figsize=(9,6))\n",
        "ax = fig.gca()\n",
        "features = YBC_df['High']\n",
        "label = YBC_df['Close']\n",
        "correlation = features.corr(label)\n",
        "plt.scatter(x=features, y=label)\n",
        "plt.xlabel('High')\n",
        "plt.ylabel('Close')\n",
        "ax.set_title('Close VS' + 'High' + '- correlation:' + str(correlation) )\n",
        "z = np.polyfit(YBC_df['High'], YBC_df['Close'], 1)\n",
        "y_hat = np.poly1d(z)(YBC_df['High'])\n",
        "\n",
        "plt.plot(YBC_df['High'], y_hat, \"r--\", lw=1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above scatter plot shows the relation between the High and close."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see that the High and Close data are Highly correlated therefore we can say that the closing price is very much dependent upon the High price of the stock."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes. The high correlation between the High and price indicates that High price will always play important role to have an idea about closing price."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "fig = plt.figure(figsize=(9,6))\n",
        "ax = fig.gca()\n",
        "features = YBC_df['Low']\n",
        "label = YBC_df['Close']\n",
        "correlation = features.corr(label)\n",
        "plt.scatter(x=features, y=label)\n",
        "plt.xlabel('Low')\n",
        "plt.ylabel('Close')\n",
        "ax.set_title('Close VS' + 'Low' + '- correlation:' + str(correlation) )\n",
        "z = np.polyfit(YBC_df['Low'], YBC_df['Close'], 1)\n",
        "y_hat = np.poly1d(z)(YBC_df['Low'])\n",
        "\n",
        "plt.plot(YBC_df['Low'], y_hat, \"r--\", lw=1)"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above scatter plot shows the relation between the Low and close."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see that the Low and Close data are Highly correlated therefore we can say that the closing price is very much dependent upon the Low price of the stock."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes. The high correlation between the Low and price indicates that Low price will always play important role to have an idea about closing price."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "plt.figure(figsize=(7,3))\n",
        "sns.heatmap(YBC_df.corr(),annot=True,cmap='coolwarm')\n"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correlation heatmaps are type of plot that visualize the strength of relationships between numerical variables. Correlation plots are used to understand which variables are related to each other and the strength of this relationship. A correlation plot typically contains a number of numerical variables with each variable represented by a column. The row represent the relationship between each pair of variables. The values in the cells indicate the strength of the relationship with positive values indicating a positive relationship and negative values indicating negative relationship.\n",
        "Therefore to show the relations between the variables we have used this plot."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above chart we can see that each and every feature here is highly correlated to each other. As the linear Regression assumes that there is no multicolinearity therefore we will try to reduce the multicolinearity using transformation of variables and generating new features."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9 - Pair plot"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair plot visualization code\n",
        "sns.pairplot(YBC_df,hue=\"Close\")\n"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pair plot is used to understand the best set of features to explain the relationship between two variables or to form the most seperated clusters. The pair plot visualizes given data to find the relationship between them where the variables can be continuous or categorical."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As i have used Close in the hue variable so the above plot will show the distribution of close with different type of columns."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As i have used close in hue variable so the above plot will show the distribution of Close with the different type of columns."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Engineering & Data Pre-processing**"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1. Handling Missing values\n",
        "\n",
        "There are no missing values and null values in the data set\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "m2-qRneEmYK2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "2.  Handling Outliers\n",
        "\n"
      ],
      "metadata": {
        "id": "StDkVllsmx2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "fig = px.box(YBC_df['Open'])\n",
        "fig.update_layout(xaxis=dict(title='Boxplot'))\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.box(np.log10(YBC_df['Open']), title= 'applied log10')\n",
        "fig.update_layout(xaxis=dict(title='Boxplot'))\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "BM8f5q5IrS67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig=px.box(YBC_df['High'])\n",
        "fig.update_layout(xaxis=dict(title='Boxplot'))\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "h9bv68AVsQyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig=px.box(YBC_df['Low'])\n",
        "fig.update_layout(xaxis=dict(title='Boxplot'))\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "hqsJprnss0nf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.box(np.log10(YBC_df['High']), title= 'applied log10')\n",
        "fig.update_layout(xaxis=dict(title='Boxplot'))\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "l_GQTo8atCSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dependent Variable Price\n",
        "plt.figure(figsize=(15,10))\n",
        "sns.distplot(np.log10(YBC_df['Close']), color='g')"
      ],
      "metadata": {
        "id": "yNLJ3SXNtVEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "YBC_df.set_index('Date', inplace=True)\n"
      ],
      "metadata": {
        "id": "TI3LEgDJuQvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Genrating a new feature to tackle the high multicolinearity\n",
        "YBC_df['average'] = YBC_df[['Open', 'High', 'Low']].mean(axis=1).round=(2)"
      ],
      "metadata": {
        "id": "Z2LlCpx4uQrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "YBC_df.head(10)"
      ],
      "metadata": {
        "id": "k5tQFeKBuQh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dependant_variable='Close'\n"
      ],
      "metadata": {
        "id": "HtE-3uIt0bwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Independant_variable=list(set(YBC_df.columns.tolist()) -{dependant_variable})"
      ],
      "metadata": {
        "id": "6DXY9kSi0boe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.log10(YBC_df[Independant_variable]).values"
      ],
      "metadata": {
        "id": "auS9D5OQ0bk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.log10(YBC_df[dependant_variable]).values"
      ],
      "metadata": {
        "id": "OJ3rzrQ10bgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. What all outlier treatment techniques have you used and why did you use those thechniques?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 3 independent features that had outliers shown in the above box plot. So to handle the outliers as well as to tackel the skewness of the dates i have transform all the numeric features to log base 10 values.\n",
        "\n",
        "After the conversion of numeric features i also have visualized them through the box plot that shows no outlier at all and information can be seen as an approx normal distribution."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature Manipulation & Selection**"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Manipulate features to minimize feature correlation and create new feature\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "def calc_vif(x):\n",
        "\n",
        "  #calculating vif\n",
        "  vif = pd.DataFrame()\n",
        "  vif['variables']=x.columns\n",
        "  vif['vif']=[variance_inflation_factor(x.values,i) for i in range(x.shape[1])]\n",
        "\n",
        "  return(vif)"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calc_vif(YBC_df [[i for i in YBC_df.describe().columns]])"
      ],
      "metadata": {
        "id": "PYzTPQ3C4UP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Transformation**"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform your data\n",
        "x= np.log10(YBC_df[Independant_variable]).values\n",
        "y= np.log10(YBC_df[dependant_variable]).values\n"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " 1.Do you think that your data needs to be transformed? If yes, which thansrormation have you used.Explain why?"
      ],
      "metadata": {
        "id": "XngmWQsY9sji"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, the datas are needed to be transformed. it has been already seen that all the independent variables and target variables are possitively skewed and they also have outliers. so to tackle both the problem i have used log 10 transformation."
      ],
      "metadata": {
        "id": "3VEJzSnE-LOb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Splitting"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split your data to train and tast. choose spliting ratio wisely.\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)"
      ],
      "metadata": {
        "id": "jkta6HmhOz5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. What data spliting ratio have you used and why?"
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here i have used the most common or standard spliting of the data set which is 80/20. 80% of the dataset is to train the algorithm and 20% is for test.\n"
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Scalling**\n"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling Your Data\n",
        "Scaler = MinMaxScaler()\n",
        "x_train = Scaler.fit_transform(x_train)\n",
        "x_test = Scaler.fit_transform(x_test)\n"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1.Which method have you used to scale your data and why ?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here I have used minmaxscaler method to scale the date since all the independant varialbes are not normally distributed. so to make sure every independant variables contribute almost equally to the analysis the minmaxscaler method is used."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7 . ML Model Implementation**"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ML Model-1**"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Linear Regression\n",
        "\n"
      ],
      "metadata": {
        "id": "KtAw58J2ZCoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML model-1 Implementation\n",
        "regressor = LinearRegression()\n",
        "\n",
        "# Fit the Algorithm\n",
        "regressor.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regressor.intercept_"
      ],
      "metadata": {
        "id": "zu4oVj7uaqKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regressor.coef_"
      ],
      "metadata": {
        "id": "tEOi1MWpa0He"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_train = regressor.predict(x_train)\n",
        "#predicting the test result\n",
        "y_pred = regressor.predict(x_test)\n"
      ],
      "metadata": {
        "id": "hQE9nlZfdHDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "id": "hn3quOhKd5eH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predicted the closing price on the test data set\n",
        "y_pred"
      ],
      "metadata": {
        "id": "w_kE_pUOeApz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we will visualize the comparison between actual values and predicted values of the target values\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(10**(y_pred))\n",
        "plt.plot(np.array(10**(y_test)))\n",
        "plt.legend([\"predicted\", \"Actual\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QqfZq-9Keumn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for Homoscadacity\n",
        "fig=px.scatter(x=10**(y_test), y=10**(y_pred), labels= {'x': 'Actual_value', 'y': 'prediction'})\n",
        "fig.add_shape(type='line', line=dict(dash='dash'), x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "AdHK75rggq6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.  # Explain the ML Model used and its performance using Evaluation metric score chart.\n",
        "\n"
      ],
      "metadata": {
        "id": "DdD-gek1jAxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# visualizing evaluation metric score chart.\n",
        "Lr_MSE=mean_squared_error(10**(y_test), 10**(y_pred))\n",
        "Lr_MSE"
      ],
      "metadata": {
        "id": "6OE5XQDDjog7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse_train=mean_squared_error(10**(y_train), 10**(y_pred_train))\n"
      ],
      "metadata": {
        "id": "TS42CyYhkVfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse_train"
      ],
      "metadata": {
        "id": "dhmj3fnqku1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train performance\n",
        "rmse_train=np.sqrt(mse_train)"
      ],
      "metadata": {
        "id": "hSFnt6nfkzfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rmse_train"
      ],
      "metadata": {
        "id": "gS8qkDVAljFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train performance\n",
        "rmse_train=np.sqrt(mse_train)"
      ],
      "metadata": {
        "id": "JR1QN2a7rVPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rmse_train"
      ],
      "metadata": {
        "id": "DUn6_Mmirol3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test performance\n",
        "Lr_RMSE = np.sqrt(Lr_MSE)\n",
        "Lr_RMSE\n"
      ],
      "metadata": {
        "id": "pInBA90dt_UM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Lr_MAE=mean_absolute_error(10**(y_test), 10**(y_pred))\n"
      ],
      "metadata": {
        "id": "7oxMPREyu0TF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Lr_MAE"
      ],
      "metadata": {
        "id": "DcZ_HsZsvX0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_absolute_percentage_error(10**(y_train), 10**(y_pred_train))\n"
      ],
      "metadata": {
        "id": "A8vb_U12vr8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Lr_MAPE=mean_absolute_percentage_error(10**(y_test), 10**(y_pred))\n",
        "Lr_MAPE"
      ],
      "metadata": {
        "id": "5jo_sWtzwFo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2_score(y_train, y_pred_train)"
      ],
      "metadata": {
        "id": "maSymtDKwdLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test performance\n",
        "Lr_R2_score=r2_score(y_test, y_pred)\n",
        "Lr_R2_score"
      ],
      "metadata": {
        "id": "YQ2BQ8jgwm03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Matrics_score=pd.DataFrame({'mean squared error':[Lr_MSE], 'root mean squared error': [Lr_RMSE], 'mean absolute error': [Lr_MAE], 'mean absolute percentage error': [Lr_MAPE],'r2_score':[Lr_R2_score]})"
      ],
      "metadata": {
        "id": "7g9EDY6VxI2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Matrics_score"
      ],
      "metadata": {
        "id": "9eP3fm1PySTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to plot model performance\n",
        "def PlotModelResults(model, x_train=x_train, x_test=x_test, plot_intervals=False):\n",
        "\n",
        "    #plot Modelled vs fact values\n",
        "     prediction = model.predict(x_test)\n",
        "\n",
        "     plt.figure(figsize=(10,5))\n",
        "     plt.plot(prediction, 'g', label=\"prediction\", linewidth=2.0)\n",
        "     plt.plot(y_test,  label= \"actual\", linewidth=2.0)\n",
        "\n",
        "\n",
        "     plt.title(\"Mean absolute percentage error {0:.2f}\".format(Lr_MAPE))\n",
        "     plt.legend(loc=\"best\")\n",
        "     plt.tight_layout()\n",
        "     plt.grid(True);\n",
        "\n",
        "PlotModelResults(regressor, plot_intervals=True)\n"
      ],
      "metadata": {
        "id": "lYAm_7ZCzNk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ML Model-2\n"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ridge Regression with cross validation"
      ],
      "metadata": {
        "id": "yWE8tWzu3b_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ridge = Ridge()\n",
        "parameters = {'alpha': [1e-15, 1e-10, 1e-8, 1e-5, 1e-4, 1e-3, 1e-2, 1, 5,10,20,30,40,45,50,55,60,100]}\n",
        "ridge_regressor= GridSearchCV(ridge, parameters, scoring='neg_mean_squared_error', cv=3)\n",
        "ridge_regressor.fit(x_train, y_train)\n"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The best fit alpha value is foud out to be:\",ridge_regressor.best_params_)\n",
        "print(\"\\nUsing\",ridge_regressor.best_params_,\" the negative mean square error is:\",ridge_regressor.best_score_)\n"
      ],
      "metadata": {
        "id": "wWX7UEpEomOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_ridge = ridge_regressor.predict(x_test)"
      ],
      "metadata": {
        "id": "A9IYiHunrX3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_ridge"
      ],
      "metadata": {
        "id": "z_A4_2mhrrv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "id": "-OEwrpY-sRGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now we will visualize the comparison between actual values and predicted values of the target variable.\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(10**(y_pred_ridge))\n",
        "plt.plot(10**(np.array(y_test)))\n",
        "plt.legend([\"predicted\",\"actual\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "obVKnWk2sTYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wIPeDEg7tqF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "R_MSE = mean_squared_error(10**(y_test), 10**(y_pred_ridge))\n",
        "print(\"MSE:\",R_MSE)\n"
      ],
      "metadata": {
        "id": "TmJhNs5etqtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "R_RMSE=np.sqrt(R_MSE)\n",
        "print(\"RMSE:\",R_RMSE)"
      ],
      "metadata": {
        "id": "gyCAMm72ubLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "R_r2 = r2_score(10**(y_test), 10**(y_pred_ridge))\n",
        "R_r2"
      ],
      "metadata": {
        "id": "5GwSRi_mv3KK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "R_MAE=mean_absolute_error(10**(y_test), 10**(y_pred_ridge))\n",
        "R_MAE"
      ],
      "metadata": {
        "id": "POLEJ8MSwJZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "R_MAPE=mean_absolute_percentage_error(10**(y_test),10**(y_pred_ridge))\n",
        "R_MAPE"
      ],
      "metadata": {
        "id": "w7ZEpkf_widf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualizing evaluation metric score chart\n",
        "Matrics_score_ridge=pd.DataFrame({'mean_squared_error':[R_MSE],'root mean squared error': [R_RMSE],'mean_absolute_error': [R_MAE], 'mean_absolute_percentage_error': [R_MAPE],'r2_score':[R_r2]})\n"
      ],
      "metadata": {
        "id": "t4YsftuYw4IB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Matrics_score_ridge"
      ],
      "metadata": {
        "id": "6PLdTFL6yW9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to plot model performance\n",
        "def PlotModelResults(model, x_train=x_train, x_test=x_test, plot_intervals=False):\n",
        "\n",
        "  #plot modelled vs fact values\n",
        "\n",
        "  prediction = model.predict(x_test)\n",
        "\n",
        "  plt.figure(figsize=(10,5))\n",
        "  plt.plot(prediction, 'g', label=\"prediction\", linewidth=2.0)\n",
        "  plt.plot(y_test, label=\"actual\", linewidth=2.0)\n",
        "\n",
        "  plt.title(\"Mean absolute percentage error {0:.2f}\".format(R_MAPE))\n",
        "  plt.legend(loc=\"best\")\n",
        "  plt.tight_layout()\n",
        "  plt.grid(True);\n",
        "\n",
        "\n",
        "PlotModelResults(ridge_regressor,plot_intervals=True)\n"
      ],
      "metadata": {
        "id": "2b9cGYVIyecM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check for Homoscadacity\n",
        "fig=px.scatter(x=10**(y_test), y=10**(y_pred_ridge), labels= {'x': 'Actual_value', 'y': 'prediction'})\n",
        "fig.add_shape(type= 'line', line=dict(dash='dash'), x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "CFgNbMJ74oHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ML Model-3"
      ],
      "metadata": {
        "id": "FmpJIPcb7K_p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LASSO Regression with cross validation**"
      ],
      "metadata": {
        "id": "GVwLWr7M7PKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lasso = Lasso(alpha=0.1, max_iter=3000)\n",
        "\n",
        "lasso.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "sY9GuzVh7h0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric score chart\n",
        "lasso.score(x_train, y_train)\n"
      ],
      "metadata": {
        "id": "1KhoBOCm73DM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_1 = lasso.predict(x_test)"
      ],
      "metadata": {
        "id": "MKTlGZzJ8la6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MSE = mean_squared_error(10**(y_test), 10**(y_pred_1))\n",
        "print(\"MSE :\", MSE)\n",
        "\n",
        "MAE= mean_absolute_error(10**(y_test), 10**(y_pred_1))\n",
        "print(\"MAE :\", MAE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE:\",RMSE)\n",
        "\n",
        "MAPE = mean_absolute_percentage_error(10**(y_test), 10**(y_pred_1))\n",
        "print(\"MAPE:\", MAPE)\n",
        "\n",
        "r2 = r2_score(10**(y_test), 10**(y_pred_1))\n",
        "print(\"r2:\", r2)\n",
        "\n"
      ],
      "metadata": {
        "id": "xilaGUxv8zem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to plot model performance\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(10**(y_pred_1))\n",
        "plt.plot(10**(np.array(y_test)))\n",
        "plt.legend([\"predicted\", \"Actual\"])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "otuT1XHqgX28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Cross - Validation and Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "AGeH-7CVhifI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lasso = Lasso()\n",
        "parameters = {'alpha': [1e-15,1e-13,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1e-1,1,5,10,20,30,40,45,50,55,60,100]}\n",
        "lasso_regressor = GridSearchCV(lasso,parameters,scoring='neg_mean_squared_error',cv=3)\n",
        "lasso_regressor.fit(x_train, y_train)\n"
      ],
      "metadata": {
        "id": "939XjZQAiDKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The best fit alpha value is found out to be:\", lasso_regressor.best_params_)\n",
        "print(\"\\nUsing\",lasso_regressor.best_params_,\"The negative mean squared error is:\", lasso_regressor.best_score_)\n"
      ],
      "metadata": {
        "id": "98Hadotqjthl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_lasso = lasso_regressor.predict(x_test)\n"
      ],
      "metadata": {
        "id": "h4hRSFBtkuJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(10**(y_pred_lasso))\n",
        "plt.plot(10**(np.array(y_test)))\n",
        "plt.legend([\"predicted\",\"Actual\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "U_qEdS2ok5uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L_MSE = mean_squared_error(10**(y_test),10**(y_pred_lasso))\n",
        "print(\"MSE:\", L_MSE)\n",
        "\n",
        "L_MAE = mean_absolute_error(10**(y_test),10**(y_pred_lasso))\n",
        "print(\"MAE:\", L_MAE)\n",
        "\n",
        "L_RMSE = np.sqrt(L_MSE)\n",
        "print(\"RMSE:\", L_RMSE)\n",
        "\n",
        "L_MAPE = mean_absolute_percentage_error(10**(y_test), 10**(y_pred_lasso))\n",
        "print(\"MAPE:\", L_MAPE)\n",
        "\n",
        "L_r2 = r2_score(10**(y_test), 10**(y_pred_lasso))\n",
        "print(\"R2:\", L_r2)\n"
      ],
      "metadata": {
        "id": "h5Q7nPTJlmv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation metric score chart\n",
        "Matrics_score_lasso=pd.DataFrame({'mean squared error':[L_MSE], 'root mean squared error':[L_RMSE], 'mean absolute error':[L_MAE], 'mean absolute percentage error': [L_MAPE],'r2_score':[L_r2]})\n",
        "Matrics_score_lasso"
      ],
      "metadata": {
        "id": "eTQ8fFFOnXJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for Homoscadacity\n",
        "fig=px.scatter(x=10**(y_test), y=10**(y_pred_lasso), labels= {'x':\"Actual_value\", 'y': \"prediction\"})\n",
        "fig.add_shape(type='line', line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "tRprYLJlqDig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the performance of the model\n",
        "def PlotModelResults(model, x_train=x_train,x_test=x_test, plot_intervals=False):\n",
        "\n",
        "   #plots modelled vs fact values\n",
        "\n",
        "   prediction = model.predict(x_test)\n",
        "\n",
        "   plt.figure(figsize=(10,5))\n",
        "   plt.plot(prediction, \"g\", label=\"prediction\", linewidth=2.0)\n",
        "   plt.plot(y_test, label=\"actual\", linewidth=2.0)\n",
        "\n",
        "   plt.title(\"Mean absolute percentage error {0:.2f}\".format(L_MAPE))\n",
        "   plt.legend(loc=\"best\")\n",
        "   plt.tight_layout()\n",
        "   plt.grid(True);\n",
        "\n",
        "\n",
        "PlotModelResults(lasso_regressor, plot_intervals=True)"
      ],
      "metadata": {
        "id": "0PQE2TKlrYEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ML Model-4"
      ],
      "metadata": {
        "id": "6jSU8ZZBkIL0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ElasticNet Regression with cross validation**"
      ],
      "metadata": {
        "id": "fLPSXGfmkMeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "elasticnet= ElasticNet(alpha=0.1, l1_ratio=0.5)"
      ],
      "metadata": {
        "id": "T6oZue4zkYpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elasticnet.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "_Up5meWVkCZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elasticnet.score(x_train,y_train)"
      ],
      "metadata": {
        "id": "09OMO0WNo34g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_en = elasticnet.predict(x_test)"
      ],
      "metadata": {
        "id": "R-6fasb_pCNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MSE = mean_squared_error(10**(y_test),10**(y_pred_en))\n",
        "print(\"MSE:\", MSE)\n",
        "\n",
        "MAE = mean_absolute_error(10**(y_test), 10**(y_pred_en))\n",
        "print(\"MAE:\", MAE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE:\", RMSE)\n",
        "\n",
        "MAPE = mean_absolute_percentage_error(10**(y_test), 10**(y_pred_en))\n",
        "print(\"MAPE:\", MAPE)\n",
        "\n",
        "r2 = r2_score(10**(y_test), 10**(y_pred_en))\n",
        "print(\"R2:\", r2)"
      ],
      "metadata": {
        "id": "d30h2XFnpUE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(10**(y_pred_en))\n",
        "plt.plot(10**(np.array(y_test)))\n",
        "plt.legend(\"predicted\", \"Actual\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "oQz9EllVrg0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elastic = ElasticNet()\n",
        "parameters = {'alpha': [1e-15,1e-13,1e-10, 1e-8,1e-5,1e-4,1e-3,1e-2,1e-1,1,5,10,20,30,40,45,50,55,60,100]}\n",
        "elastic_regressor=GridSearchCV(elastic, parameters,scoring= 'neg_mean_squared_error', cv=5)\n",
        "elastic_regressor.fit(x_train, y_train)\n"
      ],
      "metadata": {
        "id": "SZf-xXfrsIty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_elastic = elastic_regressor.predict(x_test)\n"
      ],
      "metadata": {
        "id": "ka1QEGuitZLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The best fit alpha value is found out to be:\", elastic_regressor.best_params_)\n",
        "print(\"\\nUsing\", elastic_regressor.best_params_, \"The negative mean squared error is :\", elastic_regressor.best_score_)"
      ],
      "metadata": {
        "id": "cXdZVrLTtkcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "E_MSE = mean_squared_error(10**(y_test), 10**(y_pred_elastic))\n",
        "print(\"MSE:\", E_MSE)\n",
        "\n",
        "E_MAE = mean_absolute_error(10**(y_test), 10**(y_pred_elastic))\n",
        "print(\"MAE:\", E_MAE)\n",
        "\n",
        "E_RMSE = np.sqrt(E_MSE)\n",
        "print(\"RMSE:\", E_RMSE)\n",
        "\n",
        "E_MAPE = mean_absolute_percentage_error(10**(y_test), 10**(y_pred_elastic))\n",
        "print(\"MAPE:\", E_MAPE)\n",
        "\n",
        "E_r2 = r2_score(10**(y_test), 10**(y_pred_elastic))\n",
        "print(\"R2:\", r2)"
      ],
      "metadata": {
        "id": "el80vBW2TOx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualizing evaluation Metric score chart\n",
        "Matrics_score_elastic=pd.DataFrame({'mean_squared_error': [E_MSE], 'root mean squared error':[E_RMSE], 'mean absolute error': [MAE], 'mean absolute percentage error': [E_MAPE],'r2_score':[E_r2]})"
      ],
      "metadata": {
        "id": "vrJ55gxdWNM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Matrics_score_elastic"
      ],
      "metadata": {
        "id": "H_L1MNUpXZSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(10**(y_pred_elastic))\n",
        "plt.plot(10**(np.array(y_test)))\n",
        "plt.legend([\"predicted\", \"Actual\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wMNTwTMkXh8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check for Homoscadacity\n",
        "fig= px.scatter(x=10**(y_test),y=10**(y_pred_elastic), labels= {'x': \"Actual_value\", 'y': \"prediction\"})\n",
        "fig.add_shape(type='line', line=dict(dash='dash'), x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "tU8_TbAyTwfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the performance of the model\n",
        "def PlotModelResults(model, x_train=x_train, x_test=x_test, plot_intervals=False):\n",
        "\n",
        "  #plot modelled vs fact values\n",
        "\n",
        "  prediction = model.predict(x_test)\n",
        "\n",
        "  plt.figure(figsize=(10,5))\n",
        "  plt.plot(prediction, 'g', label=\"prediction\", linewidth=2.0)\n",
        "  plt.plot(y_test, label=\"actual\", linewidth=2.0)\n",
        "\n",
        "\n",
        "  plt.title(\"Mean absolute percentage error {0:.2f}\".format(E_MAPE))\n",
        "  plt.legend(loc=\"best\")\n",
        "  plt.tight_layout()\n",
        "  plt.grid(True);\n",
        "\n",
        "PlotModelResults(elastic_regressor, plot_intervals=True)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pZ5tzY6OaQIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation Metric Summary**"
      ],
      "metadata": {
        "id": "P5B1XAmdcblW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_report=pd.DataFrame(data={'model': ['linear regression', 'ridge regression', 'lasso regression', 'elastice net regression'], 'mae': [Lr_MAE, R_MAE,L_MAE,E_MAE],'mse':[Lr_MSE,R_MSE,L_MSE,E_MSE],'r2_score':[Lr_R2_score,R_r2,L_r2,E_r2],'rmse':[Lr_RMSE,R_RMSE,L_RMSE,E_RMSE],'mape':[Lr_MAPE,R_MAPE,L_MAPE,E_MAPE]})\n",
        "model_report"
      ],
      "metadata": {
        "id": "BJlY9tKbcj6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ML Model-5**"
      ],
      "metadata": {
        "id": "TfspDz2sg5Lt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Randomforest Regression**"
      ],
      "metadata": {
        "id": "uOWorlF4g9Jw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Regressor = RandomForestRegressor()\n",
        "grid_values = {'n_estimators':[100,150,200], 'max_depth':[20,30,50,100]}\n",
        "Regressor = GridSearchCV(Regressor,param_grid = grid_values,scoring='roc_auc',cv=5)\n",
        "\n",
        "#Fit the object to train dataset\n",
        "Regressor.fit(x_train, y_train)\n"
      ],
      "metadata": {
        "id": "TN7mgTvfhEX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Best_parameters: {Regressor.best_params_}')\n"
      ],
      "metadata": {
        "id": "8LIP30WphEUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_pred = Regressor.predict(x_train)\n",
        "test_pred = Regressor.predict(x_test)"
      ],
      "metadata": {
        "id": "TkVWmVHpjJNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(test_pred)\n",
        "plt.plot(y_test)\n",
        "plt.legend(\"predicted\",\"Actual\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "T6jRPW20jkI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here for all the medels i have used grid search cross validation technique since i have already the hyper parameter numbers and also the search space that is the data set is very small. So as per my understanding grid search cv woould be the best choice to tune the hyper parameter."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. Have you seen any improvement? Note down the improvement with updates Evaluation metric score chart."
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes. after used grid search cv for each model the performance is improved. For example for lasso Regression one of the evaluation matrix the mean absolute percentage error before cross validation is MAPE: 0.7862233143141983 but after using cross validation the same evaluation matrix for the test data became MAPE:  0.08627910617139446. Therefore, it can bbe established that after using crossvalidation the performance was improved. That can be visualized also in the above plots."
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Which evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "q0Q-uW2qlZ0K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since this problem is related to regression so i would choose the room mean square error evaluation metrics for positive business impact. The root mean square error not only measures the differance between the actual and predicted values it also indicate the effect of large errors."
      ],
      "metadata": {
        "id": "apcZJJMolxYh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 4. Which ML Model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "2SnzSWo0m5a3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From all the above models for lasso and elasticnet regressions the evaluation matricses for test data set are almost close to each other. So as per my understanding we can use elasticnet regressor for now. However it will be very early to pick a model at this point of time since the dataset is very small as we need more data so that the algorithms get more training data to learn more and improve their accuracy."
      ],
      "metadata": {
        "id": "i_gi2yvxnO53"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The data set does not have any null values/missing values as well as duplicate values which made the analysis easy and smooth.\n",
        "\n",
        "* I started with univariate analysis in which it can be seen that all the variables were possitively skewed.\n",
        "* In the section of bivariate analysis it can be seen that all the independent variables are having linear Relationship with the target variables.\n",
        "* While analysing the close price with date it can be seen that there was a huge fall in the stock prices after year of 2018.\n",
        "* In correlation heatmap chart it can be clearly seen that all the variables are highly corelated to each other which is a problem for linear regression.\n",
        "*In the box plot section it can be seen that the independet variables are having some outliers.\n",
        "*Also the date column formated to year-month-date format.\n",
        "*To tackle the outliers,skewness and multicolinearity problem the data was transformed to log10 value and a new feature as average which is the mean of the prices for each row was genrated.\n",
        "*At last i have tried to implement 5 models in order to predict the closing stock prices and finally found the elastic net regression module is the be"
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your EDA Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}